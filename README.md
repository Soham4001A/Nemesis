# Nemesis: LMA-Enhanced Physics Prediction Pipeline

This project re-engineers PhysicsX's mesh-to-physical-property prediction pipeline by replacing their DiffusionNet Encoder with a novel Latent Meta Attention (LMA) encoder. The primary goal is to demonstrate superior latent compression and enhanced or equivalent downstream performance in predicting physical properties from the latent space.

## Project Goal

To develop and evaluate a new architecture that leverages Latent Meta Attention (LMA) for more efficient and effective encoding of 3D mesh data, specifically for predicting physical properties in simulation tasks. This involves a direct comparison against a baseline PhysicsX-style encoder.

## Key Objectives

1.  **Superior Latent Compression:** Achieve a more compact latent representation ($z$) without sacrificing critical geometric information.
2.  **Enhanced or Equivalent Downstream Performance:** Attain equal or better accuracy in surrogate models that predict physical properties from the latent space.
3.  **Clear Ablation Study:** Provide a rigorous, side-by-side comparison against the baseline PhysicsX-style encoder, using an identical decoder architecture for both.

## Dataset

We utilize the **MeshGraphNets** dataset from DeepMind Research. For the current implementation, we focus on the **Airfoil Flow** task, where the surrogate model predicts the **Average Pressure** from the mesh data.

## Architecture Overview

The pipeline consists of two main phases:

1.  **VAE Development (Encoder & Decoder):** Two VAEs are developed:
    *   **Baseline VAE:** Uses a DiffusionNet-style encoder.
    *   **Nemesis VAE:** Incorporates the Latent Meta Attention (LMA) encoder.
    Both VAEs share an identical Modulated ResidualNet decoder, which learns an implicit representation via a Signed Distance Function (SDF).

2.  **Surrogate Modeling Pipeline:** This phase leverages the learned latent spaces from the VAEs to predict physical properties (e.g., Average Pressure for airfoil flow). Separate surrogate models are trained for the latent spaces generated by the Baseline and Nemesis VAEs.

## Project Structure

```
Nemesis/
├── data/                     # Downloaded datasets
├── logs/                     # Training logs
├── models/                   # Saved VAE and Surrogate models
├── src/                      # Source code
│   ├── data_processing/      # Data loading and preprocessing scripts
│   ├── models/               # Model architectures (Encoders, Decoders, Surrogates)
│   ├── training/             # Training and evaluation scripts (main.py)
│   └── utils/                # Utility functions
├── TestPlan.MD               # Detailed project plan
├── README.md                 # Project overview (this file)
├── NEMESIS.md                # Details on Nemesis Architecture (LMA)
├── LGM-1.md                  # Details on Baseline Architecture
└── Instructions.md           # How to run the project
```

For detailed instructions on setting up the environment, downloading data, and running the training scripts, please refer to `Instructions.md`.